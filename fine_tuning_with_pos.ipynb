{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4109b037",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\aviad\\Desktop\\NLP-figurative-classification\\.venv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import torch\n",
    "import numpy as np\n",
    "import glob\n",
    "\n",
    "from collections import Counter\n",
    "from collections import defaultdict\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from scipy.special import softmax\n",
    "from sklearn.metrics import precision_recall_fscore_support, accuracy_score\n",
    "\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from transformers import DataCollatorForTokenClassification, RobertaPreTrainedModel, RobertaModel\n",
    "from transformers.modeling_outputs import TokenClassifierOutput\n",
    "\n",
    "\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForTokenClassification, # Added this import\n",
    "    TrainingArguments,             # Added this import\n",
    "    Trainer,                        # Added this import\n",
    ")\n",
    "\n",
    "from torch.utils.data import Dataset\n",
    "import nltk\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5386306a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"vua_dataset\"\n",
    "model_name = \"roberta-base\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f8444845",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download NLTK punkt tokenizer data if you haven't already\n",
    "# This block should be executed successfully before nltk.word_tokenize is used.\n",
    "try:\n",
    "    nltk.data.find('tokenizers/punkt')\n",
    "except LookupError: # Catching LookupError as it's the specific error for resource not found\n",
    "    print(\"NLTK 'punkt' tokenizer data not found. Downloading...\")\n",
    "    nltk.download('punkt', quiet=True) # Use quiet=True to suppress progress bar if preferred\n",
    "    print(\"NLTK 'punkt' tokenizer data downloaded.\")\n",
    "except Exception as e:\n",
    "    print(f\"An unexpected error occurred during NLTK data check/download: {e}\")\n",
    "\n",
    "try:\n",
    "    nltk.data.find('taggers/averaged_perceptron_tagger')\n",
    "except LookupError:\n",
    "    print(\"NLTK 'averaged_perceptron_tagger' not found. Downloading...\")\n",
    "    nltk.download('averaged_perceptron_tagger', quiet=True)\n",
    "    print(\"NLTK 'averaged_perceptron_tagger' downloaded.\")\n",
    "except Exception as e:\n",
    "    print(f\"An unexpected error occurred during NLTK data check/download: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b967bbc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if model_name is something like \"roberta-base\"\n",
    "if \"roberta\" in model_name.lower():\n",
    "    tokenizer = AutoTokenizer.from_pretrained(\n",
    "        model_name,\n",
    "        use_fast=True,\n",
    "        add_prefix_space=True,  # required for pre-tokenized input with RoBERTa\n",
    "    )\n",
    "else:\n",
    "    tokenizer = AutoTokenizer.from_pretrained(\n",
    "        model_name,\n",
    "        use_fast=True\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f233c43f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_process_data_with_all_features(json_path):\n",
    "    \"\"\"\n",
    "    Loads raw data from a JSONL file, groups it by sentence,\n",
    "    and processes it to include both POS and FGPOS tags.\n",
    "\n",
    "    Args:\n",
    "        json_path (str): The path to the JSONL data file.\n",
    "\n",
    "    Returns:\n",
    "        list: A list of dictionaries, each containing \"sentence_words\", \"labels\", \n",
    "              \"pos_tags\", and \"fgpos_tags\".\n",
    "        set: A set of all unique POS tags.\n",
    "        set: A set of all unique FGPOS tags.\n",
    "    \"\"\"\n",
    "    data_raw = []\n",
    "    with open(json_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        for line in f:\n",
    "            data_raw.append(json.loads(line))\n",
    "\n",
    "    sentence_groups = defaultdict(list)\n",
    "    for entry in data_raw:\n",
    "        sentence_groups[entry[\"sentence\"]].append(entry)\n",
    "\n",
    "    processed_data = []\n",
    "    all_pos_tags = set()\n",
    "    all_fgpos_tags = set()\n",
    "    for sentence, entries in sentence_groups.items():\n",
    "        entries = sorted(entries, key=lambda x: x[\"w_index\"])\n",
    "        \n",
    "        original_words = sentence.split(' ')\n",
    "        words_for_model = [original_words[e['w_index']] for e in entries]\n",
    "        \n",
    "        current_labels = [entry[\"label\"] for entry in entries]\n",
    "        pos_tags_for_sentence = [entry[\"POS\"] for entry in entries]\n",
    "        fgpos_tags_for_sentence = [entry[\"FGPOS\"] for entry in entries]\n",
    "        \n",
    "        all_pos_tags.update(pos_tags_for_sentence)\n",
    "        all_fgpos_tags.update(fgpos_tags_for_sentence)\n",
    "\n",
    "        processed_data.append({\n",
    "            \"sentence_words\": words_for_model, \n",
    "            \"labels\": current_labels,\n",
    "            \"pos_tags\": pos_tags_for_sentence,\n",
    "            \"fgpos_tags\": fgpos_tags_for_sentence\n",
    "        })\n",
    "\n",
    "    return processed_data, all_pos_tags, all_fgpos_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6d1d1a48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "POS vocabulary size: 17\n",
      "FGPOS vocabulary size: 41\n",
      "Number of training samples: 10909\n",
      "Number of test samples: 3601\n"
     ]
    }
   ],
   "source": [
    "# --- Load and process TRAIN data ---\n",
    "train_json_path = os.path.join(\"vua_dataset\", \"vua20_metaphor_train.json\")\n",
    "processed_train_data, train_pos_tags, train_fgpos_tags = load_and_process_data_with_all_features(train_json_path)\n",
    "\n",
    "# --- Load and process TEST data ---\n",
    "test_json_path = os.path.join(\"vua_dataset\", \"vua20_metaphor_test.json\")\n",
    "processed_test_data, test_pos_tags, test_fgpos_tags = load_and_process_data_with_all_features(test_json_path)\n",
    "\n",
    "# --- Create POS tag vocabulary ---\n",
    "all_pos_tags = sorted(list(train_pos_tags.union(test_pos_tags)))\n",
    "pos2id = {tag: i for i, tag in enumerate(all_pos_tags)}\n",
    "pos_vocab_size = len(pos2id)\n",
    "\n",
    "# --- Create FGPOS tag vocabulary ---\n",
    "all_fgpos_tags = sorted(list(train_fgpos_tags.union(test_fgpos_tags)))\n",
    "fgpos2id = {tag: i for i, tag in enumerate(all_fgpos_tags)}\n",
    "fgpos_vocab_size = len(fgpos2id)\n",
    "\n",
    "print(f\"POS vocabulary size: {pos_vocab_size}\")\n",
    "print(f\"FGPOS vocabulary size: {fgpos_vocab_size}\")\n",
    "print(f\"Number of training samples: {len(processed_train_data)}\")\n",
    "print(f\"Number of test samples: {len(processed_test_data)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ce7f069d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-tokenizing datasets...\n",
      "Pre-tokenizing complete.\n",
      "Pre-tokenizing complete.\n"
     ]
    }
   ],
   "source": [
    "def pre_tokenize_and_align_data(data, tokenizer, pos2id, fgpos2id):\n",
    "    \"\"\"\n",
    "    Pre-processes the entire dataset by tokenizing and aligning labels,\n",
    "    POS tags, and FGPOS tags.\n",
    "    \"\"\"\n",
    "    tokenized_data = []\n",
    "    for entry in data:\n",
    "        sentence_words = entry[\"sentence_words\"]\n",
    "        word_labels = entry[\"labels\"]\n",
    "        word_pos_tags = entry[\"pos_tags\"]\n",
    "        word_fgpos_tags = entry[\"fgpos_tags\"]\n",
    "\n",
    "        raw_encoding = tokenizer(\n",
    "            sentence_words,\n",
    "            truncation=True,\n",
    "            padding=\"max_length\",\n",
    "            max_length=128,\n",
    "            is_split_into_words=True,\n",
    "        )\n",
    "\n",
    "        word_ids = raw_encoding.word_ids(batch_index=0)\n",
    "\n",
    "        labels = []\n",
    "        pos_ids = []\n",
    "        fgpos_ids = []\n",
    "        previous_word_idx = None\n",
    "        for word_idx in word_ids:\n",
    "            if word_idx is None:\n",
    "                labels.append(-100)\n",
    "                pos_ids.append(-100)\n",
    "                fgpos_ids.append(-100)\n",
    "            elif word_idx != previous_word_idx:\n",
    "                labels.append(word_labels[word_idx])\n",
    "                pos_ids.append(pos2id[word_pos_tags[word_idx]])\n",
    "                fgpos_ids.append(fgpos2id[word_fgpos_tags[word_idx]])\n",
    "            else:\n",
    "                labels.append(-100)\n",
    "                pos_ids.append(-100)\n",
    "                fgpos_ids.append(-100)\n",
    "            previous_word_idx = word_idx\n",
    "\n",
    "        encoding = {k: torch.tensor(v) for k, v in raw_encoding.items()}\n",
    "        encoding[\"labels\"] = torch.tensor(labels, dtype=torch.long)\n",
    "        encoding[\"pos_tag_ids\"] = torch.tensor(pos_ids, dtype=torch.long)\n",
    "        encoding[\"fgpos_tag_ids\"] = torch.tensor(fgpos_ids, dtype=torch.long)\n",
    "        \n",
    "        tokenized_data.append(encoding)\n",
    "        \n",
    "    return tokenized_data\n",
    "\n",
    "# --- Pre-tokenize the datasets ---\n",
    "print(\"Pre-tokenizing datasets...\")\n",
    "train_tokenized_data = pre_tokenize_and_align_data(processed_train_data, tokenizer, pos2id, fgpos2id)\n",
    "test_tokenized_data = pre_tokenize_and_align_data(processed_test_data, tokenizer, pos2id, fgpos2id)\n",
    "print(\"Pre-tokenizing complete.\")\n",
    "\n",
    "class MetaphorDatasetWithAllFeatures(Dataset):\n",
    "    def __init__(self, tokenized_data):\n",
    "        self.tokenized_data = tokenized_data\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.tokenized_data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.tokenized_data[idx]\n",
    "        \n",
    "# --- Create Datasets from pre-tokenized data ---\n",
    "train_dataset = MetaphorDatasetWithAllFeatures(train_tokenized_data)\n",
    "test_dataset = MetaphorDatasetWithAllFeatures(test_tokenized_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5f6f3906",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RobertaForTokenClassificationWithAllPOS(RobertaPreTrainedModel):\n",
    "    def __init__(self, config, pos_vocab_size, fgpos_vocab_size, pos_embedding_dim=50, fgpos_embedding_dim=50):\n",
    "        super().__init__(config)\n",
    "        self.num_labels = config.num_labels\n",
    "        \n",
    "        self.roberta = RobertaModel(config, add_pooling_layer=False)\n",
    "        \n",
    "        self.pos_embedding = torch.nn.Embedding(pos_vocab_size, pos_embedding_dim)\n",
    "        self.fgpos_embedding = torch.nn.Embedding(fgpos_vocab_size, fgpos_embedding_dim)\n",
    "\n",
    "        # The input to the classifier is the concatenation of RoBERTa's output and all POS embeddings\n",
    "        classifier_input_size = config.hidden_size + pos_embedding_dim + fgpos_embedding_dim\n",
    "        \n",
    "        self.dropout = torch.nn.Dropout(config.hidden_dropout_prob)\n",
    "        self.classifier = torch.nn.Linear(classifier_input_size, config.num_labels)\n",
    "\n",
    "        # Initialize weights\n",
    "        self.post_init()\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        input_ids=None,\n",
    "        attention_mask=None,\n",
    "        token_type_ids=None,\n",
    "        pos_tag_ids=None,\n",
    "        fgpos_tag_ids=None,\n",
    "        labels=None, # labels is still an argument, but we won't use it here\n",
    "        **kwargs\n",
    "    ):\n",
    "        roberta_output = self.roberta(\n",
    "            input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            token_type_ids=token_type_ids,\n",
    "            **kwargs,\n",
    "        )\n",
    "        sequence_output = roberta_output[0]\n",
    "\n",
    "        # --- Get POS embeddings (Compiler-Friendly version) ---\n",
    "        pos_mask = (pos_tag_ids != -100).long()\n",
    "        valid_pos_ids = torch.clamp(pos_tag_ids, min=0)\n",
    "        pos_embeddings = self.pos_embedding(valid_pos_ids)\n",
    "        pos_embeddings = pos_embeddings * pos_mask.unsqueeze(-1)\n",
    "\n",
    "        # --- Get FGPOS embeddings (Compiler-Friendly version) ---\n",
    "        fgpos_mask = (fgpos_tag_ids != -100).long()\n",
    "        valid_fgpos_ids = torch.clamp(fgpos_tag_ids, min=0)\n",
    "        fgpos_embeddings = self.fgpos_embedding(valid_fgpos_ids)\n",
    "        fgpos_embeddings = fgpos_embeddings * fgpos_mask.unsqueeze(-1)\n",
    "\n",
    "        # Concatenate RoBERTa output with both POS embeddings\n",
    "        combined_output = torch.cat([sequence_output, pos_embeddings, fgpos_embeddings], dim=-1)\n",
    "        \n",
    "        combined_output = self.dropout(combined_output)\n",
    "        logits = self.classifier(combined_output)\n",
    "\n",
    "        # The model now ONLY returns logits. Loss calculation is handled by the Trainer.\n",
    "        return TokenClassifierOutput(\n",
    "            loss=None, # Loss is explicitly None\n",
    "            logits=logits,\n",
    "            hidden_states=roberta_output.hidden_states,\n",
    "            attentions=roberta_output.attentions,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9b3f490b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Define compute_metrics function ---\n",
    "def compute_metrics(p):\n",
    "    predictions, labels = p\n",
    "    # predictions are logits, take argmax to get predicted class\n",
    "    predictions = np.argmax(predictions, axis=2)\n",
    "\n",
    "    # Remove ignored index (where label is -100)\n",
    "    # Flatten the arrays to work with scikit-learn metrics\n",
    "    true_labels = []\n",
    "    predicted_labels = []\n",
    "    for prediction, label in zip(predictions, labels):\n",
    "        for p_val, l_val in zip(prediction, label):\n",
    "            if l_val != -100:\n",
    "                true_labels.append(l_val)\n",
    "                predicted_labels.append(p_val)\n",
    "\n",
    "    # Convert to numpy arrays\n",
    "    true_labels = np.array(true_labels)\n",
    "    predicted_labels = np.array(predicted_labels)\n",
    "\n",
    "    # Calculate precision, recall, f1-score\n",
    "    # 'binary' for 2 classes (0 and 1)\n",
    "    # 'pos_label=1' means we focus on class 1 (figurative/metaphorical) as the positive class\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(\n",
    "        true_labels, predicted_labels, average='binary', pos_label=1, zero_division=0\n",
    "    )\n",
    "    accuracy = accuracy_score(true_labels, predicted_labels)\n",
    "\n",
    "    return {\n",
    "        'accuracy': accuracy,\n",
    "        'f1': f1,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a9d2bd02",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_class_weights(train_dataset):\n",
    "    # The dataset now returns a dictionary, not a tuple\n",
    "    labels_list = [x['labels'].numpy() for x in train_dataset]\n",
    "    labels_flat = np.concatenate(labels_list)\n",
    "    labels_filtered = labels_flat[labels_flat != -100]\n",
    "    counts = Counter(labels_filtered)\n",
    "    \n",
    "    if len(counts) < 2:\n",
    "        # Handle case where one class is missing in a fold\n",
    "        return torch.tensor([1.0, 1.0], dtype=torch.float), counts, 0\n",
    "\n",
    "    total = sum(counts.values())\n",
    "    # Ensure we have counts for both classes to avoid division by zero\n",
    "    weight_0 = total / counts.get(0, 1)\n",
    "    weight_1 = total / counts.get(1, 1)\n",
    "    \n",
    "    return torch.tensor(\n",
    "        [weight_0, weight_1], dtype=torch.float\n",
    "    ), counts, total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7fd8c053",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WeightedLossTrainer(Trainer):\n",
    "    def __init__(self, *args, class_weights=None, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        # Move weights to the correct device during initialization\n",
    "        if class_weights is not None:\n",
    "            self.class_weights = class_weights.to(self.args.device)\n",
    "        else:\n",
    "            self.class_weights = None\n",
    "        \n",
    "        # Initialize the loss function once with the weights\n",
    "        self.loss_fct = CrossEntropyLoss(weight=self.class_weights)\n",
    "\n",
    "    def compute_loss(self, model, inputs, return_outputs=False, **kwargs):\n",
    "        # The model now returns outputs with loss=None. We compute it here.\n",
    "        labels = inputs.pop(\"labels\")\n",
    "        outputs = model(**inputs)\n",
    "        logits = outputs.logits\n",
    "        \n",
    "        # The loss function was already initialized with weights\n",
    "        loss = self.loss_fct(logits.view(-1, self.model.config.num_labels), labels.view(-1))\n",
    "        \n",
    "        return (loss, outputs) if return_outputs else loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c3414041",
   "metadata": {},
   "outputs": [],
   "source": [
    "K = 5  # number of folds\n",
    "kf = KFold(n_splits=K, shuffle=True, random_state=42)\n",
    "\n",
    "fold_f1s = []\n",
    "fold_precisions = []\n",
    "fold_recalls = []\n",
    "fold_losses = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c26923a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Fold 1/5 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForTokenClassificationWithAllPOS were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.bias', 'classifier.weight', 'fgpos_embedding.weight', 'pos_embedding.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='207' max='207' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [207/207 02:38, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.556700</td>\n",
       "      <td>0.308222</td>\n",
       "      <td>0.841088</td>\n",
       "      <td>0.578613</td>\n",
       "      <td>0.426668</td>\n",
       "      <td>0.898635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.316500</td>\n",
       "      <td>0.268383</td>\n",
       "      <td>0.886539</td>\n",
       "      <td>0.648674</td>\n",
       "      <td>0.519720</td>\n",
       "      <td>0.862740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.247100</td>\n",
       "      <td>0.259650</td>\n",
       "      <td>0.892862</td>\n",
       "      <td>0.663907</td>\n",
       "      <td>0.536153</td>\n",
       "      <td>0.871587</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='273' max='273' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [273/273 00:05]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model for fold 1 to results_with_all_pos_reduced_dim_compiled\\fold_1\n",
      "\n",
      "=== Fold 2/5 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForTokenClassificationWithAllPOS were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.bias', 'classifier.weight', 'fgpos_embedding.weight', 'pos_embedding.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='207' max='207' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [207/207 02:36, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.556400</td>\n",
       "      <td>0.311768</td>\n",
       "      <td>0.855953</td>\n",
       "      <td>0.593972</td>\n",
       "      <td>0.449941</td>\n",
       "      <td>0.873631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.321000</td>\n",
       "      <td>0.277898</td>\n",
       "      <td>0.890828</td>\n",
       "      <td>0.656017</td>\n",
       "      <td>0.529044</td>\n",
       "      <td>0.863185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.257300</td>\n",
       "      <td>0.266277</td>\n",
       "      <td>0.883177</td>\n",
       "      <td>0.648224</td>\n",
       "      <td>0.508935</td>\n",
       "      <td>0.892484</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='273' max='273' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [273/273 00:05]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model for fold 2 to results_with_all_pos_reduced_dim_compiled\\fold_2\n",
      "\n",
      "=== Fold 3/5 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForTokenClassificationWithAllPOS were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.bias', 'classifier.weight', 'fgpos_embedding.weight', 'pos_embedding.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='207' max='207' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [207/207 02:36, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.545600</td>\n",
       "      <td>0.310416</td>\n",
       "      <td>0.845073</td>\n",
       "      <td>0.584491</td>\n",
       "      <td>0.433470</td>\n",
       "      <td>0.897008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.313900</td>\n",
       "      <td>0.271006</td>\n",
       "      <td>0.870835</td>\n",
       "      <td>0.631424</td>\n",
       "      <td>0.483214</td>\n",
       "      <td>0.910776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.251600</td>\n",
       "      <td>0.267659</td>\n",
       "      <td>0.888331</td>\n",
       "      <td>0.659274</td>\n",
       "      <td>0.523780</td>\n",
       "      <td>0.889330</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='273' max='273' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [273/273 00:05]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model for fold 3 to results_with_all_pos_reduced_dim_compiled\\fold_3\n",
      "\n",
      "=== Fold 4/5 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForTokenClassificationWithAllPOS were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.bias', 'classifier.weight', 'fgpos_embedding.weight', 'pos_embedding.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='207' max='207' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [207/207 02:36, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.555800</td>\n",
       "      <td>0.316193</td>\n",
       "      <td>0.877796</td>\n",
       "      <td>0.612841</td>\n",
       "      <td>0.484231</td>\n",
       "      <td>0.834477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.320600</td>\n",
       "      <td>0.275644</td>\n",
       "      <td>0.872769</td>\n",
       "      <td>0.621772</td>\n",
       "      <td>0.474315</td>\n",
       "      <td>0.902278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.252800</td>\n",
       "      <td>0.263535</td>\n",
       "      <td>0.889568</td>\n",
       "      <td>0.650980</td>\n",
       "      <td>0.513646</td>\n",
       "      <td>0.888553</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='273' max='273' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [273/273 00:05]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model for fold 4 to results_with_all_pos_reduced_dim_compiled\\fold_4\n",
      "\n",
      "=== Fold 5/5 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForTokenClassificationWithAllPOS were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.bias', 'classifier.weight', 'fgpos_embedding.weight', 'pos_embedding.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='207' max='207' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [207/207 02:36, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.550900</td>\n",
       "      <td>0.311197</td>\n",
       "      <td>0.870252</td>\n",
       "      <td>0.611466</td>\n",
       "      <td>0.476541</td>\n",
       "      <td>0.852972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.320700</td>\n",
       "      <td>0.268796</td>\n",
       "      <td>0.877614</td>\n",
       "      <td>0.636606</td>\n",
       "      <td>0.493803</td>\n",
       "      <td>0.895607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.251400</td>\n",
       "      <td>0.263704</td>\n",
       "      <td>0.887325</td>\n",
       "      <td>0.654332</td>\n",
       "      <td>0.517019</td>\n",
       "      <td>0.890956</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='273' max='273' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [273/273 00:06]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model for fold 5 to results_with_all_pos_reduced_dim_compiled\\fold_5\n",
      "\n",
      "Cross-validated results over 5 folds (with POS features):\n",
      "F1: 0.6553 ± 0.0056\n",
      "Precision: 0.5199\n",
      "Recall: 0.8866\n",
      "Validation loss (mean): 0.2642\n"
     ]
    }
   ],
   "source": [
    "data_collator = DataCollatorForTokenClassification(tokenizer=tokenizer)\n",
    "\n",
    "for fold_idx, (train_idx, val_idx) in enumerate(kf.split(train_tokenized_data)):\n",
    "    print(f\"\\n=== Fold {fold_idx + 1}/{K} ===\")\n",
    "    \n",
    "    train_split = [train_tokenized_data[i] for i in train_idx]\n",
    "    val_split = [train_tokenized_data[i] for i in val_idx]\n",
    "\n",
    "    train_dataset_fold = MetaphorDatasetWithAllFeatures(train_split)\n",
    "    val_dataset_fold = MetaphorDatasetWithAllFeatures(val_split)\n",
    "\n",
    "    class_weights, _, _ = get_class_weights(train_dataset_fold)\n",
    "\n",
    "    # Instantiate the custom model for each fold\n",
    "    model = RobertaForTokenClassificationWithAllPOS.from_pretrained(\n",
    "        model_name,\n",
    "        num_labels=2,\n",
    "        pos_vocab_size=pos_vocab_size,\n",
    "        fgpos_vocab_size=fgpos_vocab_size,\n",
    "        pos_embedding_dim=50, # Can be tuned\n",
    "        fgpos_embedding_dim=20 # Reduced dimension for regularization\n",
    "    )\n",
    "\n",
    "    idx_folder = os.path.join('results_with_all_pos_reduced_dim_compiled', f'fold_{fold_idx + 1}')\n",
    "    os.makedirs(idx_folder, exist_ok=True)\n",
    "    \n",
    "    training_args = TrainingArguments(\n",
    "        output_dir=idx_folder,\n",
    "        num_train_epochs=3,\n",
    "        eval_strategy=\"epoch\",\n",
    "        save_strategy=\"no\", # We save manually at the end\n",
    "        learning_rate=2e-5,\n",
    "        per_device_train_batch_size=128, \n",
    "        per_device_eval_batch_size=8,\n",
    "        weight_decay=0.01,\n",
    "        warmup_ratio=0.1,\n",
    "        logging_steps=50,\n",
    "        seed=42 + fold_idx,\n",
    "        fp16=True, # Keep mixed-precision for performance\n",
    "        dataloader_num_workers=0,\n",
    "        dataloader_pin_memory=True, # Pin memory for faster data transfer\n",
    "        torch_compile=False, # Disabling compilation due to persistent Windows errors\n",
    "        remove_unused_columns=False, \n",
    "    )\n",
    "\n",
    "    trainer = WeightedLossTrainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=train_dataset_fold,\n",
    "        eval_dataset=val_dataset_fold,\n",
    "        compute_metrics=compute_metrics,\n",
    "        data_collator=data_collator,\n",
    "        class_weights=class_weights,\n",
    "    )\n",
    "\n",
    "    trainer.train()\n",
    "    metrics = trainer.evaluate()\n",
    "\n",
    "    fold_f1s.append(metrics[\"eval_f1\"])\n",
    "    fold_precisions.append(metrics[\"eval_precision\"])\n",
    "    fold_recalls.append(metrics[\"eval_recall\"])\n",
    "    fold_losses.append(metrics[\"eval_loss\"])\n",
    "\n",
    "    trainer.save_model(idx_folder)\n",
    "    print(f\"Saved model for fold {fold_idx + 1} to {idx_folder}\")\n",
    "\n",
    "# Aggregate results\n",
    "mean_f1 = np.mean(fold_f1s)\n",
    "std_f1 = np.std(fold_f1s)\n",
    "mean_precision = np.mean(fold_precisions)\n",
    "mean_recall = np.mean(fold_recalls)\n",
    "mean_loss = np.mean(fold_losses)\n",
    "\n",
    "print(f\"\\nCross-validated results over {K} folds (with POS features):\")\n",
    "print(f\"F1: {mean_f1:.4f} ± {std_f1:.4f}\")\n",
    "print(f\"Precision: {mean_precision:.4f}\")\n",
    "print(f\"Recall: {mean_recall:.4f}\")\n",
    "print(f\"Validation loss (mean): {mean_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "035231bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 5 models for ensemble prediction.\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Evaluating Ensemble Performance by Adjusting Vote Count ---\n",
      "Required Votes | Precision | Recall    | F1-Score  | Accuracy\n",
      "---------------------------------------------------------------\n",
      "3 of 5      | 0.4412    | 0.8004    | 0.5689    | 0.7823   \n",
      "4 of 5      | 0.4728    | 0.7539    | 0.5811    | 0.8050   \n",
      "5 of 5      | 0.5169    | 0.6936    | 0.5924    | 0.8288   \n"
     ]
    }
   ],
   "source": [
    "# --- ENSEMBLE EVALUATION ---\n",
    "\n",
    "# Load all fold models\n",
    "model_dirs = sorted(glob.glob(os.path.join(\"results_with_all_pos_reduced_dim_compiled\", \"fold_*\")))\n",
    "models = []\n",
    "for d in model_dirs:\n",
    "    if os.path.exists(os.path.join(d, \"pytorch_model.bin\")) or os.path.exists(os.path.join(d, \"model.safetensors\")):\n",
    "        model = RobertaForTokenClassificationWithAllPOS.from_pretrained(\n",
    "            d,\n",
    "            pos_vocab_size=pos_vocab_size,\n",
    "            fgpos_vocab_size=fgpos_vocab_size,\n",
    "            pos_embedding_dim=50,\n",
    "            fgpos_embedding_dim=20\n",
    "        )\n",
    "        models.append(model)\n",
    "    else:\n",
    "        print(f\"Warning: Model not found in {d}, skipping.\")\n",
    "\n",
    "print(f\"Loaded {len(models)} models for ensemble prediction.\")\n",
    "\n",
    "# Create a dummy trainer for prediction\n",
    "if models:\n",
    "    # Use a standard trainer for prediction as we don't need the weighted loss\n",
    "    # We set remove_unused_columns=True so that the 'labels' column is not passed to the model,\n",
    "    # which prevents the ValueError as the model doesn't compute loss.\n",
    "    args = TrainingArguments(\n",
    "        output_dir=\"./inference_tmp\", \n",
    "        per_device_eval_batch_size=8,\n",
    "        remove_unused_columns=True # This is key to prevent passing 'labels' to the model\n",
    "    )\n",
    "    # We only need one trainer, and we'll swap the model inside it\n",
    "    predictor = Trainer(model=models[0], args=args, data_collator=data_collator)\n",
    "\n",
    "# Create a version of the test dataset without labels for prediction\n",
    "prediction_dataset = MetaphorDatasetWithAllFeatures([\n",
    "    {k: v for k, v in item.items() if k != 'labels'} \n",
    "    for item in test_tokenized_data\n",
    "])\n",
    "\n",
    "# Get predictions\n",
    "per_model_logits = []\n",
    "for model in models:\n",
    "    predictor.model = model.to(predictor.args.device) # Move model to correct device\n",
    "    pred_out = predictor.predict(prediction_dataset) # Use the dataset without labels\n",
    "    per_model_logits.append(pred_out.predictions)\n",
    "\n",
    "per_model_logits = np.stack(per_model_logits, axis=0)\n",
    "\n",
    "# --- Analysis by Adjusting Majority Vote Threshold ---\n",
    "n_models = per_model_logits.shape[0]\n",
    "per_model_preds = np.argmax(per_model_logits, axis=-1)\n",
    "\n",
    "labels = np.stack([item['labels'].numpy() for item in test_dataset])\n",
    "mask = labels != -100\n",
    "y_true = labels[mask]\n",
    "\n",
    "print(\"\\n--- Evaluating Ensemble Performance by Adjusting Vote Count ---\")\n",
    "print(f\"Required Votes | Precision | Recall    | F1-Score  | Accuracy\")\n",
    "print(\"---------------------------------------------------------------\")\n",
    "\n",
    "for required_votes in range(int(n_models / 2) + 1, n_models + 1):\n",
    "    vote_sum = per_model_preds.sum(axis=0)\n",
    "    y_pred_at_threshold = (vote_sum[mask] >= required_votes).astype(int)\n",
    "\n",
    "    prec, rec, f1, _ = precision_recall_fscore_support(\n",
    "        y_true, y_pred_at_threshold, average=\"binary\", pos_label=1, zero_division=0\n",
    "    )\n",
    "    acc = accuracy_score(y_true, y_pred_at_threshold)\n",
    "\n",
    "    print(f\"{required_votes} of {n_models}      | {prec:<9.4f} | {rec:<9.4f} | {f1:<9.4f} | {acc:<9.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
