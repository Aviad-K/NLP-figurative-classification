{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0b90df0b",
   "metadata": {},
   "source": [
    "# Train a model on linguistic features in order to classify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "63ac2deb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import joblib\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.metrics import accuracy_score, classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea9eb939",
   "metadata": {},
   "source": [
    "# Data pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e852004e",
   "metadata": {},
   "outputs": [],
   "source": [
    "basline_directory = \"baseline\"\n",
    "dataset_dir = 'vua_dataset'\n",
    "train_file = os.path.join(dataset_dir, 'vua20_metaphor_train.json')\n",
    "test_file = os.path.join(dataset_dir, 'vua20_metaphor_test.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5000b8f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the bert embeddings\n",
    "bert_embeddings = np.load(os.path.join('bert_embeddings', 'bert_embeddings.npz'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "439ebf35",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = bert_embeddings['train_embeddings']\n",
    "X_test = bert_embeddings['test_embeddings']\n",
    "y_train = bert_embeddings['train_labels']\n",
    "y_test = bert_embeddings['test_labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "88dd863c",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(train_file, 'r', encoding='utf-8') as f:\n",
    "    train_data = [json.loads(line) for line in f]\n",
    "with open(test_file, 'r', encoding='utf-8') as f:\n",
    "    test_data = [json.loads(line) for line in f]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e02982fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_features(dataset, embeddings, vectorizer=None):\n",
    "    pos_features = [{'POS': item['POS'], 'FGPOS': item['FGPOS']} for item in dataset]\n",
    "    labels = np.array([item['label'] for item in dataset])\n",
    "    if vectorizer is None:\n",
    "        vectorizer = DictVectorizer(sparse=False)\n",
    "        pos_features_vectorized = vectorizer.fit_transform(pos_features)\n",
    "    else:\n",
    "        pos_features_vectorized = vectorizer.transform(pos_features)\n",
    "    combined_features = np.hstack([embeddings, pos_features_vectorized])\n",
    "    return combined_features, labels, vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2fd0f449",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_combined_features, train_labels, vectorizer = prepare_features(train_data, X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5812db46",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_combined_features, test_labels, _ = prepare_features(test_data, X_test, vectorizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d044d217",
   "metadata": {},
   "source": [
    "# Models using only parts of speech "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "8b102e83",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model_class, X_train, y_train, **kwargs):\n",
    "    model = model_class(**kwargs)\n",
    "    model.fit(X_train, y_train)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "a005d6e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_and_evaluate(model, X_test, y_test):\n",
    "    predictions = model.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, predictions)\n",
    "    report = classification_report(y_test, predictions)\n",
    "    return predictions, accuracy, report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "ff0541fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_results(accuracy, report):\n",
    "    print(f\"Accuracy: {accuracy}\")\n",
    "    print(\"Classification Report:\")\n",
    "    print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f80c704f",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "1180bd8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_model_pos = train_model(LogisticRegression, X_train, y_train, max_iter=1000, class_weight='balanced')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "126db71a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6442151739052081\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.64      0.75     18214\n",
      "           1       0.29      0.65      0.40      3982\n",
      "\n",
      "    accuracy                           0.64     22196\n",
      "   macro avg       0.59      0.65      0.57     22196\n",
      "weighted avg       0.79      0.64      0.68     22196\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lr_pos_predictions, lr_pos_accuracy, lr_pos_report = predict_and_evaluate(lr_model_pos, X_test, y_test)\n",
    "print_results(lr_pos_accuracy, lr_pos_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7d2f22c",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "eed493e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_model_pos = train_model(RandomForestClassifier, X_train, y_train, n_estimators=100, class_weight='balanced', random_state=42, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "35675c89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8205983060010813\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      1.00      0.90     18214\n",
      "           1       0.50      0.00      0.00      3982\n",
      "\n",
      "    accuracy                           0.82     22196\n",
      "   macro avg       0.66      0.50      0.45     22196\n",
      "weighted avg       0.76      0.82      0.74     22196\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rf_pos_predictions, rf_pos_accuracy, rf_pos_report = predict_and_evaluate(rf_model_pos, X_test, y_test)\n",
    "print_results(rf_pos_accuracy, rf_pos_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "683a1f32",
   "metadata": {},
   "source": [
    "## KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "0f01e769",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_model_pos = train_model(KNeighborsClassifier, X_train, y_train, n_neighbors=5, weights='distance')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "961b5826",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8190664984681925\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.97      0.90     18214\n",
      "           1       0.48      0.13      0.20      3982\n",
      "\n",
      "    accuracy                           0.82     22196\n",
      "   macro avg       0.66      0.55      0.55     22196\n",
      "weighted avg       0.77      0.82      0.77     22196\n",
      "\n"
     ]
    }
   ],
   "source": [
    "knn_pos_predictions, knn_pos_accuracy, knn_pos_report = predict_and_evaluate(knn_model_pos, X_test, y_test)\n",
    "print_results(knn_pos_accuracy, knn_pos_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4731ef84",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "dae0a94b",
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_model_pos = train_model(LinearSVC, X_train, y_train, max_iter=1000, class_weight='balanced')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "04b117e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6436745359524239\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.64      0.75     18214\n",
      "           1       0.28      0.65      0.40      3982\n",
      "\n",
      "    accuracy                           0.64     22196\n",
      "   macro avg       0.59      0.65      0.57     22196\n",
      "weighted avg       0.78      0.64      0.68     22196\n",
      "\n"
     ]
    }
   ],
   "source": [
    "svm_pos_predictions, svm_pos_accuracy, svm_pos_report = predict_and_evaluate(svm_model_pos, X_test, y_test)\n",
    "print_results(svm_pos_accuracy, svm_pos_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "cc019659",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['baseline_models/svm_pos.joblib']"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.makedirs(\"baseline_models\", exist_ok=True)\n",
    "\n",
    "# Save models\n",
    "joblib.dump(lr_model_pos, \"baseline_models/logistic_regression_pos.joblib\")\n",
    "joblib.dump(rf_model_pos, \"baseline_models/random_forest_pos.joblib\")\n",
    "joblib.dump(knn_model_pos, \"baseline_models/knn_pos.joblib\")\n",
    "joblib.dump(svm_model_pos, \"baseline_models/svm_pos.joblib\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ccd1c2b",
   "metadata": {},
   "source": [
    "# Models using parts of speech and embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95ea1ab7",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "84bf977a",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_model = train_model(LogisticRegression, train_combined_features, train_labels, max_iter=1000, class_weight='balanced')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "1450564c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6033519553072626\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.57      0.70     18214\n",
      "           1       0.28      0.78      0.41      3982\n",
      "\n",
      "    accuracy                           0.60     22196\n",
      "   macro avg       0.60      0.67      0.56     22196\n",
      "weighted avg       0.81      0.60      0.65     22196\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lr_predictions, lr_accuracy, lr_report = predict_and_evaluate(lr_model, test_combined_features, test_labels)\n",
    "print_results(lr_accuracy, lr_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "064ef774",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21ef6bc6",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m rf_model \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_model\u001b[49m(RandomForestClassifier, train_combined_features, train_labels, n_estimators\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'train_model' is not defined"
     ]
    }
   ],
   "source": [
    "rf_model = train_model(RandomForestClassifier, train_combined_features, train_labels, n_estimators=100, class_weight='balanced', random_state=42, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "0092df95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8210488376284015\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      1.00      0.90     18214\n",
      "           1       0.92      0.00      0.01      3982\n",
      "\n",
      "    accuracy                           0.82     22196\n",
      "   macro avg       0.87      0.50      0.45     22196\n",
      "weighted avg       0.84      0.82      0.74     22196\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rf_predictions, rf_accuracy, rf_report = predict_and_evaluate(rf_model, test_combined_features, test_labels)\n",
    "print_results(rf_accuracy, rf_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a95c07a9",
   "metadata": {},
   "source": [
    "## KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "eb6dfbc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_model = train_model(KNeighborsClassifier, train_combined_features, train_labels, n_neighbors=5, weights='distance')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "18ba7c21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8201477743737611\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.97      0.90     18214\n",
      "           1       0.50      0.13      0.21      3982\n",
      "\n",
      "    accuracy                           0.82     22196\n",
      "   macro avg       0.67      0.55      0.55     22196\n",
      "weighted avg       0.78      0.82      0.77     22196\n",
      "\n"
     ]
    }
   ],
   "source": [
    "knn_predictions, knn_accuracy, knn_report = predict_and_evaluate(knn_model, test_combined_features, test_labels)\n",
    "print_results(knn_accuracy, knn_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bee65b2",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "0effdf78",
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_model = train_model(LinearSVC, train_combined_features, train_labels, max_iter=1000, class_weight='balanced')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "fe975d2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5969544061993152\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.56      0.69     18214\n",
      "           1       0.28      0.78      0.41      3982\n",
      "\n",
      "    accuracy                           0.60     22196\n",
      "   macro avg       0.60      0.67      0.55     22196\n",
      "weighted avg       0.81      0.60      0.64     22196\n",
      "\n"
     ]
    }
   ],
   "source": [
    "svm_predictions, svm_accuracy, svm_report = predict_and_evaluate(svm_model, test_combined_features, test_labels)\n",
    "print_results(svm_accuracy, svm_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "09f96e17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['baseline_models/knn_pos_and_embeddings.joblib']"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.makedirs(\"baseline_models\", exist_ok=True)\n",
    "\n",
    "# Save models\n",
    "joblib.dump(lr_model, \"baseline_models/logistic_regression_pos_and_embeddings.joblib\")\n",
    "joblib.dump(rf_model, \"baseline_models/random_forest_pos_and_embeddings.joblib\")\n",
    "joblib.dump(knn_model, \"baseline_models/knn_pos_and_embeddings.joblib\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c319fe9",
   "metadata": {},
   "source": [
    "# Error Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3cf68175",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_misclassified(predictions, test_labels=test_labels):\n",
    "    return set(i for i, (p, t) in enumerate(zip(predictions, test_labels)) if p != t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "bf683ced",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num of common misclassified errors: 800\n",
      "All common errors are figurative: True\n",
      "Number of figurative data points is: 3982\n"
     ]
    }
   ],
   "source": [
    "# Collect misclassified indices for each model\n",
    "lr_errors = get_misclassified(lr_predictions)\n",
    "rf_errors = get_misclassified(rf_predictions)\n",
    "knn_errors = get_misclassified(knn_predictions)\n",
    "svm_errors = get_misclassified(svm_predictions)\n",
    "\n",
    "# Intersection: indices misclassified by all models\n",
    "common_errors = lr_errors & rf_errors & knn_errors & svm_errors\n",
    "print(f\"Num of common misclassified errors: {len(common_errors)}\")\n",
    "# Check if all common errors are on figurative (label 1) data points\n",
    "all_figurative = all(test_data[i]['label'] == 1 for i in common_errors)\n",
    "print(f\"All common errors are figurative: {all_figurative}\")\n",
    "print(f\"Number of figurative data points is: {sum(1 for entry in test_data if entry['label'] == 1)}\")\n",
    "\n",
    "\n",
    "# # Print sentences for these indices\n",
    "# for i in common_errors:\n",
    "#     entry = test_data[i]\n",
    "#     print(\n",
    "#         f\"Sentence: {entry['sentence']}\\n\"\n",
    "#         f\"Word index: {entry['w_index']}\\n\"\n",
    "#         f\"POS: {entry['POS']}, FGPOS: {entry['FGPOS']}\\n\"\n",
    "#         f\"True label: {entry['label']}\\n\"\n",
    "#         \"-----\"\n",
    "#     )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "304cd561",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "e6ca1500",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num of errors: 8804\n",
      "Number of figurative classified as literal is: 895\n"
     ]
    }
   ],
   "source": [
    "print(f\"Num of errors: {len(lr_errors)}\")\n",
    "print(f\"Number of figurative classified as literal is: {sum(1 for i in lr_errors if test_data[i]['label'] == 1)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e729b5c",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "27071a11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num of errors: 3972\n",
      "Number of figurative classified as literal is: 3971\n"
     ]
    }
   ],
   "source": [
    "print(f\"Num of errors: {len(rf_errors)}\")\n",
    "print(f\"Number of figurative classified as literal is: {sum(1 for i in rf_errors if test_data[i]['label'] == 1)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96813672",
   "metadata": {},
   "source": [
    "## KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "0cc2c353",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num of errors: 3992\n",
      "Number of figurative classified as literal is: 3455\n"
     ]
    }
   ],
   "source": [
    "print(f\"Num of errors: {len(knn_errors)}\")\n",
    "print(f\"Number of figurative classified as literal is: {sum(1 for i in knn_errors if test_data[i]['label'] == 1)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29a8b314",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "fd6ab0f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num of errors: 8946\n",
      "Number of figurative classified as literal is: 859\n"
     ]
    }
   ],
   "source": [
    "print(f\"Num of errors: {len(svm_errors)}\")\n",
    "print(f\"Number of figurative classified as literal is: {sum(1 for i in svm_errors if test_data[i]['label'] == 1)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fea0f14",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
