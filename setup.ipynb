{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "01867880",
   "metadata": {},
   "source": [
    "# Environment Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9dc02df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Installing required packages for local GPU environment...\n",
      "==================================================\n",
      "‚úì torch already installed (version: 2.7.1+cu128)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\aviad\\Desktop\\HW\\Current HW\\current HW\\NLP\\final project\\.venv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì transformers already installed (version: 4.54.1)\n",
      "‚úì datasets already installed\n",
      "‚úì scikit-learn already installed (version: 1.7.1)\n",
      "‚úì numpy already installed (version: 2.2.6)\n",
      "‚úì tqdm already installed\n",
      "==================================================\n",
      "Setup complete! Ready to proceed with GPU-accelerated training.\n"
     ]
    }
   ],
   "source": [
    "# Initial setup for local GPU environment\n",
    "import subprocess\n",
    "import sys\n",
    "\n",
    "def install_package(package):\n",
    "    \"\"\"Install a package using pip\"\"\"\n",
    "    try:\n",
    "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", package])\n",
    "        print(f\"‚úì {package} installed successfully\")\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(f\"‚úó Failed to install {package}: {e}\")\n",
    "\n",
    "# List of required packages\n",
    "required_packages = [\n",
    "    \"torch\",\n",
    "    \"transformers[torch]\",\n",
    "    \"datasets\",\n",
    "    \"scikit-learn\",\n",
    "    \"numpy\",\n",
    "    \"tqdm\"\n",
    "]\n",
    "\n",
    "print(\"Installing required packages for local GPU environment...\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "for package in required_packages:\n",
    "    try:\n",
    "        # Try to import first\n",
    "        if package == \"torch\":\n",
    "            import torch\n",
    "            print(f\"‚úì torch already installed (version: {torch.__version__})\")\n",
    "        elif package == \"transformers[torch]\":\n",
    "            import transformers\n",
    "            print(f\"‚úì transformers already installed (version: {transformers.__version__})\")\n",
    "        elif package == \"datasets\":\n",
    "            import datasets\n",
    "            print(f\"‚úì datasets already installed\")\n",
    "        elif package == \"scikit-learn\":\n",
    "            import sklearn\n",
    "            print(f\"‚úì scikit-learn already installed (version: {sklearn.__version__})\")\n",
    "        elif package == \"numpy\":\n",
    "            import numpy\n",
    "            print(f\"‚úì numpy already installed (version: {numpy.__version__})\")\n",
    "        elif package == \"tqdm\":\n",
    "            import tqdm\n",
    "            print(f\"‚úì tqdm already installed\")\n",
    "    except ImportError:\n",
    "        print(f\"Installing {package}...\")\n",
    "        install_package(package)\n",
    "\n",
    "print(\"=\" * 50)\n",
    "print(\"Setup complete! Ready to proceed with GPU-accelerated training.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0347f74d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "12.8\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.is_available())\n",
    "print(torch.version.cuda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bf25527b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "GPU: NVIDIA GeForce GTX 1070\n",
      "CUDA Version: 12.8\n",
      "PyTorch Version: 2.7.1+cu128\n",
      "Available GPU memory: 8.0 GB\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import os\n",
    "\n",
    "# Set your Hugging Face token\n",
    "os.environ['HUGGINGFACE_HUB_TOKEN'] = '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'\n",
    "\n",
    "# Check for GPU availability and set device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"CUDA Version: {torch.version.cuda}\")\n",
    "    print(f\"PyTorch Version: {torch.__version__}\")\n",
    "    print(f\"Available GPU memory: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f} GB\")\n",
    "else:\n",
    "    print(\"CUDA is not available. Using CPU.\")\n",
    "    print(\"Warning: BERT embedding extraction will be much slower on CPU!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59d990ad",
   "metadata": {},
   "source": [
    "# Data Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6e406a7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"CreativeLang/vua20_metaphor\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "41f60e3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üóÇÔ∏è  Checking VUA dataset files in organized structure...\n",
      "üìÅ Target directory: vua_dataset/\n",
      "üíæ Saving dataset files to vua_dataset/...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating json from Arrow format: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 161/161 [00:00<00:00, 353.85ba/s]\n",
      "Creating json from Arrow format: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 23/23 [00:00<00:00, 383.33ba/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Saved vua20_metaphor_train.json to vua_dataset/\n",
      "‚úÖ Saved vua20_metaphor_test.json to vua_dataset/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Create vua_dataset directory if it doesn't exist\n",
    "dataset_dir = 'vua_dataset'\n",
    "os.makedirs(dataset_dir, exist_ok=True)\n",
    "\n",
    "# Define file paths within the vua_dataset folder\n",
    "train_file = os.path.join(dataset_dir, 'vua20_metaphor_train.json')\n",
    "test_file = os.path.join(dataset_dir, 'vua20_metaphor_test.json')\n",
    "\n",
    "print(\"üóÇÔ∏è  Checking VUA dataset files in organized structure...\")\n",
    "print(f\"üìÅ Target directory: {dataset_dir}/\")\n",
    "\n",
    "if os.path.exists(train_file) and os.path.exists(test_file):\n",
    "    print(f\"‚úÖ Dataset files already exist in {dataset_dir}/:\")\n",
    "    print(f\"   - {os.path.basename(train_file)}\")\n",
    "    print(f\"   - {os.path.basename(test_file)}\")\n",
    "    \n",
    "    # Show file sizes\n",
    "    train_size = os.path.getsize(train_file) / (1024*1024)\n",
    "    test_size = os.path.getsize(test_file) / (1024*1024)\n",
    "    print(f\"üìä File sizes: Train={train_size:.1f}MB, Test={test_size:.1f}MB\")\n",
    "    print(\"‚è© Skipping dataset save operation - using existing files.\")\n",
    "else:\n",
    "    print(f\"üíæ Saving dataset files to {dataset_dir}/...\")\n",
    "    dataset['train'].to_json(train_file)\n",
    "    dataset['test'].to_json(test_file)\n",
    "    print(f\"‚úÖ Saved {os.path.basename(train_file)} to {dataset_dir}/\")\n",
    "    print(f\"‚úÖ Saved {os.path.basename(test_file)} to {dataset_dir}/\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
